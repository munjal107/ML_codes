{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_Seq2Seq_EncoderDecoder.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ncd1sfDd-cofoZwJAwFjppTWZCZk6gxm","authorship_tag":"ABX9TyNIXDlF2d2nAY7rDr9q8Y9h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HOqjMcvfFcfS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593600638974,"user_tz":-330,"elapsed":1309,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"19abbd37-9986-4db6-9a25-2b1b5ed40fd9"},"source":["%cd drive/My Drive/GOOGLE-COLAB/data"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/GOOGLE-COLAB/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qt4PsvlZ7sk7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600641482,"user_tz":-330,"elapsed":3793,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input,LSTM,Dense"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhAm-ZDoEcuG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600641484,"user_tz":-330,"elapsed":3776,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["batch_size = 64\n","epochs = 100\n","latent_dim = 256\n","num_samples = 10000\n","data_path = 'fra.txt'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMNq_xAvG-Po","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593600642185,"user_tz":-330,"elapsed":4436,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"f1bf2663-6ce8-477d-c9f0-2a76f36d2042"},"source":["df = pd.read_table(data_path)\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Go.</th>\n","      <th>Va !</th>\n","      <th>CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #1158250 (Wittydev)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Who?</td>\n","      <td>Qui ?</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Go.  ... CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n","0   Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n","1   Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n","2  Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n","3  Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n","4  Who?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...                             \n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2QYgDuITGYRC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593600642798,"user_tz":-330,"elapsed":4987,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"f8f4c549-4644-487e-92d1-3fb81e4d52b5"},"source":["df = pd.read_table(data_path,usecols=[0,1],names=['eng','fra'])\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Salut.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eng       fra\n","0   Go.      Va !\n","1   Hi.   Salut !\n","2   Hi.    Salut.\n","3  Run!   Cours !\n","4  Run!  Courez !"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"rjmWtYHcF12A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600642800,"user_tz":-330,"elapsed":4954,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["with open(data_path,'r',encoding='utf-8') as f:\n","  lines = f.read().split('\\n')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiU1AYL-F_Zz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1593600642801,"user_tz":-330,"elapsed":4927,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"7b114492-1ac2-4f95-ea7d-10e9d93c2011"},"source":["print(len(lines))\n","print(*lines[:5],sep='\\n')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["177211\n","Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n","Hi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\n","Hi.\tSalut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\n","Run!\tCours !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\n","Run!\tCourez !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2crw5vpZHoHR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593600642803,"user_tz":-330,"elapsed":4895,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"3338bc3b-2e07-4cf4-d422-d72f603d0743"},"source":["lines[0].split('\\t')"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Go.',\n"," 'Va !',\n"," 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"g13nbH3BFlcB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600642806,"user_tz":-330,"elapsed":4868,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["input_texts = []\n","target_texts = []\n","input_charcters = set()\n","target_charcters = set()\n","\n","for line in lines[:min(num_samples,len(lines)-1)]:\n","  input_text,target_text, _ = line.split('\\t')\n","  # We use \"tab\" as the \"start sequence\" character\n","  # for the targets, and \"\\n\" as \"end sequence\" character.\n","  target_text = '\\t' + target_text + '\\n'\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  \n","  for char in input_text:\n","    if char not in input_charcters:\n","      input_charcters.add(char)\n","\n","  for char in target_text:\n","    if char not in target_charcters:\n","      target_charcters.add(char)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zewioIAOidC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1593600642806,"user_tz":-330,"elapsed":4832,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"69b867f5-fd99-448d-bfe5-a0f17174882b"},"source":["input_charcters = sorted(input_charcters)\n","target_charcters = sorted(target_charcters)\n","\n","print(input_charcters)\n","print(target_charcters)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[' ', '!', '$', '%', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é']\n","['\\t', '\\n', ' ', '!', '%', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '’', '\\u202f']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OrOvJ_5EP4VE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593600642807,"user_tz":-330,"elapsed":4803,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"e59ddd84-7037-4734-8522-6770e2e3b285"},"source":["num_encoder_tokens = len(input_charcters)\n","num_decoder_tokens = len(target_charcters)\n","\n","print(num_encoder_tokens,num_decoder_tokens)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["71 92\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EcUOQG4mQGJB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593600642808,"user_tz":-330,"elapsed":4773,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"34d834e3-6fee-4d94-e403-1d1d0ebe6a25"},"source":["max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print(max_encoder_seq_length,max_decoder_seq_length)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["16 59\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u4CyuCS8QeGZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593600642808,"user_tz":-330,"elapsed":4730,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"5649ae4e-c761-4671-a775-2509f6ab9edf"},"source":["print(input_texts[100])\n","print(target_texts[100])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Come in.\n","\tEntre.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1EuWWjSJQy_F","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600642809,"user_tz":-330,"elapsed":4667,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["input_token_index = dict([(char,i)for i,char in enumerate(input_charcters)])\n","target_token_index = dict([(char,i)for i,char in enumerate(target_charcters)])\n","\n","# print(input_token_index)\n","# print(target_token_index)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkVeaRKnRymr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593600642810,"user_tz":-330,"elapsed":4645,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"e863b61e-0bb2-4b69-db11-3cefc7da915a"},"source":["input_token_index,target_token_index"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({' ': 0,\n","  '!': 1,\n","  '$': 2,\n","  '%': 3,\n","  '&': 4,\n","  \"'\": 5,\n","  ',': 6,\n","  '-': 7,\n","  '.': 8,\n","  '0': 9,\n","  '1': 10,\n","  '2': 11,\n","  '3': 12,\n","  '5': 13,\n","  '6': 14,\n","  '7': 15,\n","  '8': 16,\n","  '9': 17,\n","  ':': 18,\n","  '?': 19,\n","  'A': 20,\n","  'B': 21,\n","  'C': 22,\n","  'D': 23,\n","  'E': 24,\n","  'F': 25,\n","  'G': 26,\n","  'H': 27,\n","  'I': 28,\n","  'J': 29,\n","  'K': 30,\n","  'L': 31,\n","  'M': 32,\n","  'N': 33,\n","  'O': 34,\n","  'P': 35,\n","  'Q': 36,\n","  'R': 37,\n","  'S': 38,\n","  'T': 39,\n","  'U': 40,\n","  'V': 41,\n","  'W': 42,\n","  'Y': 43,\n","  'a': 44,\n","  'b': 45,\n","  'c': 46,\n","  'd': 47,\n","  'e': 48,\n","  'f': 49,\n","  'g': 50,\n","  'h': 51,\n","  'i': 52,\n","  'j': 53,\n","  'k': 54,\n","  'l': 55,\n","  'm': 56,\n","  'n': 57,\n","  'o': 58,\n","  'p': 59,\n","  'q': 60,\n","  'r': 61,\n","  's': 62,\n","  't': 63,\n","  'u': 64,\n","  'v': 65,\n","  'w': 66,\n","  'x': 67,\n","  'y': 68,\n","  'z': 69,\n","  'é': 70},\n"," {'\\t': 0,\n","  '\\n': 1,\n","  ' ': 2,\n","  '!': 3,\n","  '%': 4,\n","  '&': 5,\n","  \"'\": 6,\n","  '(': 7,\n","  ')': 8,\n","  ',': 9,\n","  '-': 10,\n","  '.': 11,\n","  '0': 12,\n","  '1': 13,\n","  '2': 14,\n","  '3': 15,\n","  '5': 16,\n","  '8': 17,\n","  '9': 18,\n","  ':': 19,\n","  '?': 20,\n","  'A': 21,\n","  'B': 22,\n","  'C': 23,\n","  'D': 24,\n","  'E': 25,\n","  'F': 26,\n","  'G': 27,\n","  'H': 28,\n","  'I': 29,\n","  'J': 30,\n","  'K': 31,\n","  'L': 32,\n","  'M': 33,\n","  'N': 34,\n","  'O': 35,\n","  'P': 36,\n","  'Q': 37,\n","  'R': 38,\n","  'S': 39,\n","  'T': 40,\n","  'U': 41,\n","  'V': 42,\n","  'Y': 43,\n","  'a': 44,\n","  'b': 45,\n","  'c': 46,\n","  'd': 47,\n","  'e': 48,\n","  'f': 49,\n","  'g': 50,\n","  'h': 51,\n","  'i': 52,\n","  'j': 53,\n","  'k': 54,\n","  'l': 55,\n","  'm': 56,\n","  'n': 57,\n","  'o': 58,\n","  'p': 59,\n","  'q': 60,\n","  'r': 61,\n","  's': 62,\n","  't': 63,\n","  'u': 64,\n","  'v': 65,\n","  'x': 66,\n","  'y': 67,\n","  'z': 68,\n","  '\\xa0': 69,\n","  '«': 70,\n","  '»': 71,\n","  'À': 72,\n","  'Ç': 73,\n","  'É': 74,\n","  'Ê': 75,\n","  'à': 76,\n","  'â': 77,\n","  'ç': 78,\n","  'è': 79,\n","  'é': 80,\n","  'ê': 81,\n","  'ë': 82,\n","  'î': 83,\n","  'ï': 84,\n","  'ô': 85,\n","  'ù': 86,\n","  'û': 87,\n","  'œ': 88,\n","  '\\u2009': 89,\n","  '’': 90,\n","  '\\u202f': 91})"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"S6tYwV2vSBtz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600642810,"user_tz":-330,"elapsed":4601,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8hOG2XFVklN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1593600643210,"user_tz":-330,"elapsed":4966,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"8c1d3774-415f-40ab-9da4-d41fa215c0aa"},"source":["print(encoder_input_data.shape)\n","print(encoder_input_data[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["(10000, 16, 71)\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aX9LHq9kWro8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593600643211,"user_tz":-330,"elapsed":4948,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"59a2102b-15d8-4b2e-92b4-dad4e69492c7"},"source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    print(input_text)\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1. # after end of send each place is filled with space\n","    print(t + 1, input_token_index[' '])\n","    # for i in encoder_input_data[i]:\n","    #   print(i)\n","    break\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Go.\n","3 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OJvF2aIIXon8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600643212,"user_tz":-330,"elapsed":4934,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7UVOboUVmG5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600643609,"user_tz":-330,"elapsed":5320,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["for i, (input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n","  for t,char in enumerate(input_text):\n","    encoder_input_data[i,t,input_token_index[char]] == 1. \n","  encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n","\n","  for t, char in enumerate(target_text):\n","    # decoder_target_data is ahead of decoder_input_data by one timestep\n","    decoder_input_data[i, t, target_token_index[char]] = 1.\n","    if t > 0:\n","      # decoder_target_data will be ahead by one timestep\n","      # and will not include the start character.\n","      decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","      \n","  decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n","  decoder_target_data[i, t:, target_token_index[' ']] = 1."],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"reEgX9U6YcC5","colab_type":"text"},"source":["### Start Building the Model"]},{"cell_type":"code","metadata":{"id":"GvJeZ9R8XptA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600644711,"user_tz":-330,"elapsed":6410,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Define an input sequence and process it.'\n","encoder_inputs = Input(shape=(None,num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KceHrThY_Ji","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600644717,"user_tz":-330,"elapsed":6395,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n","                                     initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJFonUt0Zjyp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593600644721,"user_tz":-330,"elapsed":6381,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Run training\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFuvsZp5Zzjh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1593600644724,"user_tz":-330,"elapsed":6353,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"aa50b7f0-9c4d-4cb5-937b-f9d3c1ee39f0"},"source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 71)]   0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None, 92)]   0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 256), (None, 335872      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 256),  357376      input_2[0][0]                    \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 92)     23644       lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 716,892\n","Trainable params: 716,892\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SaOE6guaZ02J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593601075529,"user_tz":-330,"elapsed":437142,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"5b9c5846-1284-4747-c4f5-aece99bd711f"},"source":["model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","125/125 [==============================] - 6s 45ms/step - loss: 1.2002 - accuracy: 0.7243 - val_loss: 1.0708 - val_accuracy: 0.7028\n","Epoch 2/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.8661 - accuracy: 0.7666 - val_loss: 0.8566 - val_accuracy: 0.7625\n","Epoch 3/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.7065 - accuracy: 0.8025 - val_loss: 0.7481 - val_accuracy: 0.7858\n","Epoch 4/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.6243 - accuracy: 0.8203 - val_loss: 0.6844 - val_accuracy: 0.7999\n","Epoch 5/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.5791 - accuracy: 0.8309 - val_loss: 0.6406 - val_accuracy: 0.8119\n","Epoch 6/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.5465 - accuracy: 0.8401 - val_loss: 0.6216 - val_accuracy: 0.8175\n","Epoch 7/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.5201 - accuracy: 0.8475 - val_loss: 0.5901 - val_accuracy: 0.8233\n","Epoch 8/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4976 - accuracy: 0.8534 - val_loss: 0.5694 - val_accuracy: 0.8305\n","Epoch 9/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4777 - accuracy: 0.8585 - val_loss: 0.5590 - val_accuracy: 0.8338\n","Epoch 10/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4590 - accuracy: 0.8641 - val_loss: 0.5449 - val_accuracy: 0.8359\n","Epoch 11/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4427 - accuracy: 0.8683 - val_loss: 0.5287 - val_accuracy: 0.8423\n","Epoch 12/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4277 - accuracy: 0.8724 - val_loss: 0.5206 - val_accuracy: 0.8432\n","Epoch 13/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4136 - accuracy: 0.8768 - val_loss: 0.5116 - val_accuracy: 0.8470\n","Epoch 14/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.4009 - accuracy: 0.8802 - val_loss: 0.5020 - val_accuracy: 0.8491\n","Epoch 15/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3891 - accuracy: 0.8838 - val_loss: 0.4990 - val_accuracy: 0.8500\n","Epoch 16/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3779 - accuracy: 0.8866 - val_loss: 0.4964 - val_accuracy: 0.8513\n","Epoch 17/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3677 - accuracy: 0.8897 - val_loss: 0.4913 - val_accuracy: 0.8542\n","Epoch 18/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3574 - accuracy: 0.8925 - val_loss: 0.4879 - val_accuracy: 0.8547\n","Epoch 19/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3486 - accuracy: 0.8949 - val_loss: 0.4868 - val_accuracy: 0.8555\n","Epoch 20/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3399 - accuracy: 0.8977 - val_loss: 0.4869 - val_accuracy: 0.8562\n","Epoch 21/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3314 - accuracy: 0.9001 - val_loss: 0.4848 - val_accuracy: 0.8572\n","Epoch 22/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3239 - accuracy: 0.9022 - val_loss: 0.4821 - val_accuracy: 0.8585\n","Epoch 23/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3164 - accuracy: 0.9043 - val_loss: 0.4810 - val_accuracy: 0.8582\n","Epoch 24/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3090 - accuracy: 0.9066 - val_loss: 0.4844 - val_accuracy: 0.8577\n","Epoch 25/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.3022 - accuracy: 0.9086 - val_loss: 0.4855 - val_accuracy: 0.8583\n","Epoch 26/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2957 - accuracy: 0.9103 - val_loss: 0.4835 - val_accuracy: 0.8570\n","Epoch 27/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2894 - accuracy: 0.9120 - val_loss: 0.4882 - val_accuracy: 0.8573\n","Epoch 28/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2837 - accuracy: 0.9139 - val_loss: 0.4907 - val_accuracy: 0.8573\n","Epoch 29/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2779 - accuracy: 0.9154 - val_loss: 0.4936 - val_accuracy: 0.8572\n","Epoch 30/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2726 - accuracy: 0.9170 - val_loss: 0.4947 - val_accuracy: 0.8575\n","Epoch 31/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2674 - accuracy: 0.9188 - val_loss: 0.4951 - val_accuracy: 0.8583\n","Epoch 32/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2626 - accuracy: 0.9201 - val_loss: 0.5014 - val_accuracy: 0.8577\n","Epoch 33/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2579 - accuracy: 0.9213 - val_loss: 0.5015 - val_accuracy: 0.8581\n","Epoch 34/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2534 - accuracy: 0.9230 - val_loss: 0.5076 - val_accuracy: 0.8577\n","Epoch 35/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2490 - accuracy: 0.9240 - val_loss: 0.5038 - val_accuracy: 0.8578\n","Epoch 36/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2452 - accuracy: 0.9253 - val_loss: 0.5086 - val_accuracy: 0.8576\n","Epoch 37/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2411 - accuracy: 0.9265 - val_loss: 0.5130 - val_accuracy: 0.8569\n","Epoch 38/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2375 - accuracy: 0.9274 - val_loss: 0.5180 - val_accuracy: 0.8581\n","Epoch 39/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2338 - accuracy: 0.9284 - val_loss: 0.5208 - val_accuracy: 0.8579\n","Epoch 40/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2307 - accuracy: 0.9293 - val_loss: 0.5275 - val_accuracy: 0.8571\n","Epoch 41/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2272 - accuracy: 0.9303 - val_loss: 0.5319 - val_accuracy: 0.8564\n","Epoch 42/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2245 - accuracy: 0.9312 - val_loss: 0.5315 - val_accuracy: 0.8558\n","Epoch 43/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2219 - accuracy: 0.9321 - val_loss: 0.5376 - val_accuracy: 0.8560\n","Epoch 44/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2188 - accuracy: 0.9328 - val_loss: 0.5366 - val_accuracy: 0.8567\n","Epoch 45/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2162 - accuracy: 0.9335 - val_loss: 0.5445 - val_accuracy: 0.8553\n","Epoch 46/100\n","125/125 [==============================] - 4s 35ms/step - loss: 0.2137 - accuracy: 0.9341 - val_loss: 0.5510 - val_accuracy: 0.8535\n","Epoch 47/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2111 - accuracy: 0.9348 - val_loss: 0.5553 - val_accuracy: 0.8541\n","Epoch 48/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2088 - accuracy: 0.9357 - val_loss: 0.5534 - val_accuracy: 0.8557\n","Epoch 49/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2063 - accuracy: 0.9364 - val_loss: 0.5640 - val_accuracy: 0.8540\n","Epoch 50/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2043 - accuracy: 0.9369 - val_loss: 0.5651 - val_accuracy: 0.8548\n","Epoch 51/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2022 - accuracy: 0.9374 - val_loss: 0.5702 - val_accuracy: 0.8547\n","Epoch 52/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.2003 - accuracy: 0.9378 - val_loss: 0.5749 - val_accuracy: 0.8536\n","Epoch 53/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1983 - accuracy: 0.9386 - val_loss: 0.5759 - val_accuracy: 0.8544\n","Epoch 54/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1964 - accuracy: 0.9389 - val_loss: 0.5796 - val_accuracy: 0.8540\n","Epoch 55/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1947 - accuracy: 0.9396 - val_loss: 0.5781 - val_accuracy: 0.8550\n","Epoch 56/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1929 - accuracy: 0.9398 - val_loss: 0.5848 - val_accuracy: 0.8537\n","Epoch 57/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1913 - accuracy: 0.9406 - val_loss: 0.5963 - val_accuracy: 0.8520\n","Epoch 58/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1899 - accuracy: 0.9406 - val_loss: 0.5946 - val_accuracy: 0.8544\n","Epoch 59/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1880 - accuracy: 0.9413 - val_loss: 0.6014 - val_accuracy: 0.8509\n","Epoch 60/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1868 - accuracy: 0.9415 - val_loss: 0.6075 - val_accuracy: 0.8518\n","Epoch 61/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1851 - accuracy: 0.9420 - val_loss: 0.6045 - val_accuracy: 0.8527\n","Epoch 62/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1842 - accuracy: 0.9421 - val_loss: 0.6055 - val_accuracy: 0.8538\n","Epoch 63/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1824 - accuracy: 0.9428 - val_loss: 0.6127 - val_accuracy: 0.8513\n","Epoch 64/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1814 - accuracy: 0.9429 - val_loss: 0.6131 - val_accuracy: 0.8530\n","Epoch 65/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1801 - accuracy: 0.9431 - val_loss: 0.6176 - val_accuracy: 0.8524\n","Epoch 66/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1790 - accuracy: 0.9435 - val_loss: 0.6197 - val_accuracy: 0.8530\n","Epoch 67/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1779 - accuracy: 0.9438 - val_loss: 0.6254 - val_accuracy: 0.8510\n","Epoch 68/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1765 - accuracy: 0.9442 - val_loss: 0.6262 - val_accuracy: 0.8508\n","Epoch 69/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1757 - accuracy: 0.9444 - val_loss: 0.6354 - val_accuracy: 0.8524\n","Epoch 70/100\n","125/125 [==============================] - 4s 33ms/step - loss: 0.1748 - accuracy: 0.9445 - val_loss: 0.6370 - val_accuracy: 0.8516\n","Epoch 71/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1737 - accuracy: 0.9448 - val_loss: 0.6422 - val_accuracy: 0.8504\n","Epoch 72/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1727 - accuracy: 0.9448 - val_loss: 0.6394 - val_accuracy: 0.8509\n","Epoch 73/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1719 - accuracy: 0.9452 - val_loss: 0.6437 - val_accuracy: 0.8504\n","Epoch 74/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1709 - accuracy: 0.9455 - val_loss: 0.6509 - val_accuracy: 0.8498\n","Epoch 75/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1702 - accuracy: 0.9455 - val_loss: 0.6615 - val_accuracy: 0.8485\n","Epoch 76/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1693 - accuracy: 0.9457 - val_loss: 0.6560 - val_accuracy: 0.8492\n","Epoch 77/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1683 - accuracy: 0.9461 - val_loss: 0.6577 - val_accuracy: 0.8493\n","Epoch 78/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1675 - accuracy: 0.9464 - val_loss: 0.6599 - val_accuracy: 0.8500\n","Epoch 79/100\n","125/125 [==============================] - 4s 33ms/step - loss: 0.1668 - accuracy: 0.9464 - val_loss: 0.6653 - val_accuracy: 0.8484\n","Epoch 80/100\n","125/125 [==============================] - 4s 33ms/step - loss: 0.1660 - accuracy: 0.9466 - val_loss: 0.6720 - val_accuracy: 0.8487\n","Epoch 81/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1653 - accuracy: 0.9468 - val_loss: 0.6719 - val_accuracy: 0.8476\n","Epoch 82/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1648 - accuracy: 0.9467 - val_loss: 0.6750 - val_accuracy: 0.8474\n","Epoch 83/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1640 - accuracy: 0.9472 - val_loss: 0.6794 - val_accuracy: 0.8485\n","Epoch 84/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1634 - accuracy: 0.9472 - val_loss: 0.6818 - val_accuracy: 0.8482\n","Epoch 85/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1627 - accuracy: 0.9474 - val_loss: 0.6770 - val_accuracy: 0.8481\n","Epoch 86/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1620 - accuracy: 0.9474 - val_loss: 0.6830 - val_accuracy: 0.8485\n","Epoch 87/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1614 - accuracy: 0.9476 - val_loss: 0.6881 - val_accuracy: 0.8481\n","Epoch 88/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1608 - accuracy: 0.9476 - val_loss: 0.6887 - val_accuracy: 0.8473\n","Epoch 89/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1603 - accuracy: 0.9479 - val_loss: 0.6947 - val_accuracy: 0.8473\n","Epoch 90/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1596 - accuracy: 0.9480 - val_loss: 0.6972 - val_accuracy: 0.8465\n","Epoch 91/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1594 - accuracy: 0.9481 - val_loss: 0.7041 - val_accuracy: 0.8457\n","Epoch 92/100\n","125/125 [==============================] - 4s 33ms/step - loss: 0.1588 - accuracy: 0.9481 - val_loss: 0.7011 - val_accuracy: 0.8476\n","Epoch 93/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1582 - accuracy: 0.9482 - val_loss: 0.6992 - val_accuracy: 0.8475\n","Epoch 94/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1579 - accuracy: 0.9482 - val_loss: 0.7043 - val_accuracy: 0.8459\n","Epoch 95/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1572 - accuracy: 0.9484 - val_loss: 0.7052 - val_accuracy: 0.8457\n","Epoch 96/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1569 - accuracy: 0.9486 - val_loss: 0.7067 - val_accuracy: 0.8460\n","Epoch 97/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1564 - accuracy: 0.9485 - val_loss: 0.7117 - val_accuracy: 0.8465\n","Epoch 98/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1560 - accuracy: 0.9486 - val_loss: 0.7226 - val_accuracy: 0.8453\n","Epoch 99/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1554 - accuracy: 0.9487 - val_loss: 0.7168 - val_accuracy: 0.8451\n","Epoch 100/100\n","125/125 [==============================] - 4s 34ms/step - loss: 0.1553 - accuracy: 0.9488 - val_loss: 0.7165 - val_accuracy: 0.8466\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdf026ca828>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"QASK21p4Z5pQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601076402,"user_tz":-330,"elapsed":437998,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Save model\n","model.save('s2s.h5')"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLeqzM4v_x9I","colab_type":"text"},"source":["#### For prediction"]},{"cell_type":"code","metadata":{"id":"GjsXs4jB--RZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601076988,"user_tz":-330,"elapsed":438569,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Next: inference mode (sampling).\n","# Here's the drill:\n","# 1) encode input and retrieve initial decoder state\n","# 2) run one step of decoder with this initial state\n","# and a \"start of sequence\" token as target.\n","# Output will be the next target token\n","# 3) Repeat with the current target token and current states\n","\n","# Define sampling models\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-6hpvhq_zwp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601076991,"user_tz":-330,"elapsed":438560,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"el7iNavy_1fa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601076993,"user_tz":-330,"elapsed":438548,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAvAmExz_3Z5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1593601081317,"user_tz":-330,"elapsed":442856,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}},"outputId":"3d089fac-954d-429f-c001-a835a8dd8a29"},"source":["for seq_index in range(10):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: Go.\n","Decoded sentence: Salut !\n","\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut !\n","\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut !\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Courez !\n","\n","-\n","Input sentence: Run!\n","Decoded sentence: Courez !\n","\n","-\n","Input sentence: Who?\n","Decoded sentence: Courez !\n","\n","-\n","Input sentence: Wow!\n","Decoded sentence: Courez !\n","\n","-\n","Input sentence: Fire!\n","Decoded sentence: Attends !\n","\n","-\n","Input sentence: Help!\n","Decoded sentence: Attends !\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: Attends !\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6phjvxbv_4pC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601081319,"user_tz":-330,"elapsed":442855,"user":{"displayName":"Munjal Desai","photoUrl":"","userId":"03895475279741389989"}}},"source":[""],"execution_count":31,"outputs":[]}]}